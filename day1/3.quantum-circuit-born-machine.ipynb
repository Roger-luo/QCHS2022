{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Quantum Circuit Born Machine"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Yao is designed with variational quantum circuits in mind, and this tutorial\n",
    "will introduce how to use Yao for this kind of task by implementing a quantum\n",
    "circuit born machine described in [Jin-Guo Liu, Lei Wang (2018)](https://arxiv.org/abs/1804.04168)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "let's use the packages first"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Yao, LinearAlgebra, Plots"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training Target"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this tutorial, we will ask the variational circuit to learn the most basic\n",
    "distribution: a guassian distribution. It is defined as follows:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "$$\n",
    "f(x \\left| \\mu, \\sigma^2\\right) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We implement it as `gaussian_pdf`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function gaussian_pdf(x, μ::Real, σ::Real)\n",
    "    pl = @. 1 / sqrt(2pi * σ^2) * exp(-(x - μ)^2 / (2 * σ^2))\n",
    "    pl / sum(pl)\n",
    "end\n",
    "pg = gaussian_pdf(1:1<<6, 1<<5-0.5, 1<<4);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can plot the distribution, it looks like"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "plot(pg)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create the Circuit"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A quantum circuit born machine looks like the following:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![differentiable ciruit](assets/differentiable.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "It is composited by two different layers: **rotation layer** and **entangler layer**."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Rotation Layer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Arbitrary rotation is built with **Rotation Gate** on **Z, X, Z** axis\n",
    "with parameters."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "$$\n",
    "Rz(\\theta) \\cdot Rx(\\theta) \\cdot Rz(\\theta)\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since our input will be a $|0\\dots 0\\rangle$ state.\n",
    "The first layer of arbitrary rotation can just\n",
    "use $Rx(\\theta) \\cdot Rz(\\theta)$ and the last\n",
    "layer of arbitrary rotation could just\n",
    "use $Rz(\\theta)\\cdot Rx(\\theta)$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In **幺**, every Hilbert operator is a **block** type, this\n",
    "ncludes all **quantum gates** and **quantum oracles**.\n",
    "In general, operators appears in a quantum circuit\n",
    "can be divided into **Composite Blocks** and **Primitive Blocks**."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We follow the low abstraction principle and\n",
    "thus each block represents a certain approach\n",
    "of calculation. The simplest **Composite Block**\n",
    "is a **Chain Block**, which chains other blocks\n",
    "(oracles) with the same number of qubits together.\n",
    "It is just a simple mathematical composition of\n",
    "operators with same size. e.g."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "$$\n",
    "\\text{chain(X, Y, Z)} \\iff X \\cdot Y \\cdot Z\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can construct an arbitrary rotation block by chain $Rz$, $Rx$, $Rz$ together."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "chain(Rz(0.0), Rx(0.0), Rz(0.0))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "`Rx`, `Rz` will construct new rotation gate,\n",
    "which are just shorthands for `rot(X, 0.0)`, etc."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then let's chain them up"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "layer(nbit::Int, x::Symbol) = layer(nbit, Val(x))\n",
    "layer(nbit::Int, ::Val{:first}) = chain(nbit, put(i=>chain(Rx(0), Rz(0))) for i = 1:nbit);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We do not need to feed the first `n` parameter into `put` here.\n",
    "All factory methods can be **lazy** evaluate **the first arguements**, which is the number of qubits.\n",
    "It will return a lambda function that requires a single interger input.\n",
    "The instance of desired block will only be constructed until all the information is filled.\n",
    "When you filled all the information in somewhere of the declaration, 幺 will be able to infer the others.\n",
    "We will now define the rest of rotation layers"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "layer(nbit::Int, ::Val{:last}) = chain(nbit, put(i=>chain(Rz(0), Rx(0))) for i = 1:nbit)\n",
    "layer(nbit::Int, ::Val{:mid}) = chain(nbit, put(i=>chain(Rz(0), Rx(0), Rz(0))) for i = 1:nbit);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Entangler"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Another component of quantum circuit born machine are\n",
    "several **CNOT** operators applied on different qubits."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "entangler(pairs) = chain(control(ctrl, target=>X) for (ctrl, target) in pairs);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can then define such a born machine"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function build_circuit(n, nlayers, pairs)\n",
    "    circuit = chain(n)\n",
    "    push!(circuit, layer(n, :first))\n",
    "    for i in 2:nlayers\n",
    "        push!(circuit, cache(entangler(pairs)))\n",
    "        push!(circuit, layer(n, :mid))\n",
    "    end\n",
    "    push!(circuit, cache(entangler(pairs)))\n",
    "    push!(circuit, layer(n, :last))\n",
    "    return circuit\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We use the method `cache` here to tag the entangler block that it\n",
    "should be cached after its first run, because it is actually a\n",
    "constant oracle. Let's see what will be constructed"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "build_circuit(4, 1, [1=>2, 2=>3, 3=>4])"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MMD Loss & Gradients"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The MMD loss is describe below:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathcal{L} &= \\left| \\sum_{x} p \\theta(x) \\phi(x) - \\sum_{x} \\pi(x) \\phi(x) \\right|^2\\\\\n",
    "            &= \\langle K(x, y) \\rangle_{x \\sim p_{\\theta}, y\\sim p_{\\theta}} - 2 \\langle K(x, y) \\rangle_{x\\sim p_{\\theta}, y\\sim \\pi} + \\langle K(x, y) \\rangle_{x\\sim\\pi, y\\sim\\pi}\n",
    "\\end{aligned}\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will use a squared exponential kernel here."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "struct RBFKernel\n",
    "    σ::Float64\n",
    "    m::Matrix{Float64}\n",
    "end\n",
    "\n",
    "function RBFKernel(σ::Float64, space)\n",
    "    dx2 = (space .- space').^2\n",
    "    return RBFKernel(σ, exp.(-1/2σ * dx2))\n",
    "end\n",
    "\n",
    "kexpect(κ::RBFKernel, x, y) = x' * κ.m * y"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are two different way to define the loss:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In simulation we can use the probability distribution of the state directly"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "get_prob(qcbm) = probs(zero_state(nqubits(qcbm)) |> qcbm)\n",
    "\n",
    "function loss(κ, c, target)\n",
    "    p = get_prob(c) - target\n",
    "    return kexpect(κ, p, p)\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Or if you want to simulate the whole process with measurement (which is entirely\n",
    "physical), you should define the loss with measurement results, for convenience\n",
    "we directly use the simulated results as our loss"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Gradients\n",
    "the gradient of MMD loss is"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\theta^i_l} &= \\langle K(x, y) \\rangle_{x\\sim p_{\\theta^+}, y\\sim p_{\\theta}} - \\langle K(x, y) \\rangle_{x\\sim p_{\\theta}^-, y\\sim p_{\\theta}}\\\\\n",
    "&- \\langle K(x, y) \\rangle _{x\\sim p_{\\theta^+}, y\\sim\\pi} + \\langle K(x, y) \\rangle_{x\\sim p_{\\theta^-}, y\\sim\\pi}\n",
    "\\end{aligned}\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "which can be implemented as"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function gradient(qcbm, κ, ptrain)\n",
    "    n = nqubits(qcbm)\n",
    "    prob = get_prob(qcbm)\n",
    "    grad = zeros(Float64, nparameters(qcbm))\n",
    "\n",
    "    count = 1\n",
    "    for k in 1:2:length(qcbm), each_line in qcbm[k], gate in content(each_line)\n",
    "        dispatch!(+, gate, π/2)\n",
    "        prob_pos = probs(zero_state(n) |> qcbm)\n",
    "\n",
    "        dispatch!(-, gate, π)\n",
    "        prob_neg = probs(zero_state(n) |> qcbm)\n",
    "\n",
    "        dispatch!(+, gate, π/2) # set back\n",
    "\n",
    "        grad_pos = kexpect(κ, prob, prob_pos) - kexpect(κ, prob, prob_neg)\n",
    "        grad_neg = kexpect(κ, ptrain, prob_pos) - kexpect(κ, ptrain, prob_neg)\n",
    "        grad[count] = grad_pos - grad_neg\n",
    "        count += 1\n",
    "    end\n",
    "    return grad\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's setup the training"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import Optimisers\n",
    "qcbm = build_circuit(6, 10, [1=>2, 3=>4, 5=>6, 2=>3, 4=>5, 6=>1])\n",
    "dispatch!(qcbm, :random) # initialize the parameters\n",
    "\n",
    "κ = RBFKernel(0.25, 0:2^6-1)\n",
    "pg = gaussian_pdf(1:1<<6, 1<<5-0.5, 1<<4);\n",
    "opt = Optimisers.setup(Optimisers.ADAM(0.01), parameters(qcbm));\n",
    "\n",
    "function train(qcbm, κ, opt, target)\n",
    "    history = Float64[]\n",
    "    for _ in 1:100\n",
    "        push!(history, loss(κ, qcbm, target))\n",
    "        ps = parameters(qcbm)\n",
    "        Optimisers.update!(opt, ps, gradient(qcbm, κ, target))\n",
    "        dispatch!(qcbm, ps)\n",
    "    end\n",
    "    return history\n",
    "end\n",
    "\n",
    "history = train(qcbm, κ, opt, pg)\n",
    "trained_pg = probs(zero_state(nqubits(qcbm)) |> qcbm)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The history of training looks like below"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "title!(\"training history\")\n",
    "xlabel!(\"steps\"); ylabel!(\"loss\")\n",
    "plot(history)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "And let's check what we got"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "fig2 = plot(1:1<<6, trained_pg; label=\"trained\")\n",
    "plot!(fig2, 1:1<<6, pg; label=\"target\")\n",
    "title!(\"distribution\")\n",
    "xlabel!(\"x\"); ylabel!(\"p\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "So within 50 steps, we got a pretty close estimation of our\n",
    "target distribution!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  },
  "kernelspec": {
   "name": "julia-1.7",
   "display_name": "Julia 1.7.3",
   "language": "julia"
  }
 },
 "nbformat": 4
}
